{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d2b4b6-102b-4578-9360-4c1600ad9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "from mugato.data.utils import create_combined_dataloader\n",
    "from mugato.mugato import MugatoConfig, Mugato, TransformerConfig\n",
    "from mugato.nano_gpt import Block\n",
    "from mugato.utils import data_home, select_device, generic_collate_fn\n",
    "from mugato.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fc94fb-8dab-4c96-8b8f-7795da09c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 6\n",
    "n_head = 4\n",
    "n_embd = 512\n",
    "bias = False\n",
    "dropout = 0.0\n",
    "block_size=768\n",
    "batch_size=4\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b09b1c7-35cd-43ca-a24b-9068da015ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer = tiktoken.get_encoding(\"r50k_base\")\n",
    "tokenizer = Tokenizer(text_tokenizer)\n",
    "train_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"train\", block_size=block_size))\n",
    "val_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"val\", block_size=block_size))\n",
    "test_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"test\", block_size=block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aafef35-b094-4a3f-8ddb-f8e86d4c07bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 450, 66, 32988, 995, 0]\n",
      "Hello, abcDEF world!\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.text_tokenizer.encode(\"Hello, abcDEF world!\"))\n",
    "print(tokenizer.text_tokenizer.decode(tokenizer.text_tokenizer.encode(\"Hello, abcDEF world!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5e6928-c325-4934-81dd-43b862a569b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     token:       text\n",
      "     15496:      Hello\n",
      "        11:          ,\n",
      "       450:         ab\n",
      "        66:          c\n",
      "     32988:        DEF\n",
      "       995:      world\n",
      "         0:          !\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"token\":>10}: {\"text\":>10}')\n",
    "for token in tokenizer.text_tokenizer.encode(\"Hello, abcDEF world!\"):\n",
    "    decoded = tokenizer.text_tokenizer.decode([token])\n",
    "    print(f'{token:>10}: {decoded:>10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ac4b3c-40e7-4b25-9abd-b170bbf34f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55307d4-b1ce-4d56-af4b-9ffced79baba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 1024)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.n_text, tokenizer.n_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f60d8bca-4ddb-45a8-831b-d0e00180eb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496],\n",
       "        [   11],\n",
       "        [  995],\n",
       "        [    0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_text(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd5ff9d-72e3-4091-8398-1d7259cf353f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50258])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_discrete(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d0a2d74-c28b-49d1-82f0-ff210c35c2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode_text(torch.tensor([[50256]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5711e3e4-55d8-44d3-89f5-53944b875465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50257])\n",
      "tensor([50258])\n",
      "tensor([50259])\n",
      "tensor([50260])\n",
      "tensor([50261])\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(tokenizer.encode_discrete(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf51e28-6b8d-4099-a27f-6fbbe359ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "transformer_model_args = dict(\n",
    "    n_layer=n_layer,\n",
    "    n_head=n_head,\n",
    "    n_embd=n_embd,\n",
    "    block_size=block_size,\n",
    "    bias=bias,\n",
    "    vocab_size=50257,  # tiktoken.get_encoding(\"r50k_base\").n_vocab\n",
    "    dropout=dropout,\n",
    ")  # start with model_args from command line\n",
    "\n",
    "mugato_model_args = dict(\n",
    "    n_embd=n_embd,\n",
    "    block_size=block_size,\n",
    "    vocab_size=51281,  # text vocab + discrete vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f150a25a-67c6-43b4-9281-e78459805552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "transformer_config = TransformerConfig(**transformer_model_args)\n",
    "transformer = nn.ModuleDict(\n",
    "    dict(\n",
    "        wpe=nn.Embedding(transformer_config.block_size, transformer_config.n_embd),\n",
    "        drop=nn.Dropout(transformer_config.dropout),\n",
    "        h=nn.ModuleList(\n",
    "            [\n",
    "                Block(transformer_config)\n",
    "                for _ in range(transformer_config.n_layer)\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "mugato_config = MugatoConfig(**mugato_model_args)\n",
    "untrained_model = Mugato(tokenizer, transformer, mugato_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68b1d3e-b3b6-43ef-8d5e-ecd92ce103eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_model = untrained_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6865710-feab-4b3f-9c13-df8882eee4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d58431-7367-45ef-9aac-c2f560900712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mugato(\n",
       "  (lookup_embedding): Embedding(51281, 512)\n",
       "  (image_embedding): ResNetV2(\n",
       "    (stem): Sequential(\n",
       "      (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ResNetStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): PreActBottleneck(\n",
       "            (downsample): DownsampleConv(\n",
       "              (conv): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): Identity()\n",
       "            )\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): PreActBottleneck(\n",
       "            (downsample): DownsampleConv(\n",
       "              (conv): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (norm): Identity()\n",
       "            )\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): PreActBottleneck(\n",
       "            (downsample): DownsampleConv(\n",
       "              (conv): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (norm): Identity()\n",
       "            )\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResNetStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): PreActBottleneck(\n",
       "            (downsample): DownsampleConv(\n",
       "              (conv): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (norm): Identity()\n",
       "            )\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 2048, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): PreActBottleneck(\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 2048, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): GroupNormAct(\n",
       "      32, 2048, eps=1e-05, affine=True\n",
       "      (drop): Identity()\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "  )\n",
       "  (transformer): ModuleDict(\n",
       "    (wpe): Embedding(768, 512)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (c_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=51281, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36c0e788-1c92-4fde-b004-a1b83254ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_model.eval()\n",
    "text = \"First Citizen:\\n\"\n",
    "tokens = torch.stack([torch.concat([torch.tensor([tokenizer.eot_token_id]).unsqueeze(0), tokenizer.encode_text(text)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7586a42e-e03b-43d9-84e2-bc765da8060c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xs \u001b[38;5;241m=\u001b[39m OrderedDict(text\u001b[38;5;241m=\u001b[39m\u001b[43mtokens\u001b[49m)\n\u001b[1;32m      2\u001b[0m xs, ys, ms \u001b[38;5;241m=\u001b[39m generic_collate_fn([[xs, xs]])\n\u001b[1;32m      3\u001b[0m next_word_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "xs = OrderedDict(text=tokens)\n",
    "xs, ys, ms = generic_collate_fn([[xs, xs]])\n",
    "next_word_token = None\n",
    "i = 0\n",
    "xs, ys, ms = [x.to(device) for x in [xs, ys, ms]]\n",
    "with torch.no_grad():\n",
    "    logits, loss = untrained_model(xs, pad=False)\n",
    "temp = 0.6\n",
    "scaled_logits = logits / temp\n",
    "probs = scaled_logits.softmax(dim=2)\n",
    "next_word_token = torch.multinomial(probs[0, [-1]], num_samples=1)\n",
    "next_word = tokenizer.decode_text(next_word_token)\n",
    "text += next_word\n",
    "tokens = torch.stack([tokenizer.encode_text(text)])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d81f0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mugato.data.four_rooms import (\n",
    "    initialize as initialize_four_rooms, \n",
    "    create_dataloader as create_four_rooms_dataloader, \n",
    "    tokenize as four_rooms_tokenize\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fba69a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.2002, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_rooms_dataset = initialize_four_rooms()\n",
    "four_rooms_dataloader = create_four_rooms_dataloader(tokenizer, batch_size=batch_size, split=\"test\")\n",
    "batch = next(iter(four_rooms_dataloader))\n",
    "X, Y, M = batch\n",
    "X, Y, M = X.to(device), Y.to(device), M.to(device)\n",
    "logits, loss = untrained_model(X, Y, M)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e820997",
   "metadata": {},
   "source": [
    "# Test Four Rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "352786cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = four_rooms_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9707593",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "732e3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = test_data.recover_environment(render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "obs['direction'] = np.array([obs['direction']])\n",
    "obs['image'] = np.array([obs['image']])\n",
    "obs['mission'] = [obs['mission']]\n",
    "dummy_action = 0  # Will be sliced off after sequencing.\n",
    "obs['action'] = np.array([dummy_action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83a9bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mugato.data.four_rooms import four_rooms_to_rgb\n",
    "from mugato.utils import image_transform\n",
    "from mugato.utils import Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9b7417d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1023"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "228fa569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(obs):\n",
    "    mission_tokens = [\n",
    "        tokenizer.encode_text(mission)\n",
    "        for mission in obs[\"mission\"]\n",
    "    ]\n",
    "    direction_tokens = [\n",
    "        tokenizer.encode_discrete([direction])\n",
    "        for direction in obs[\"direction\"]\n",
    "    ]\n",
    "    _image = obs[\"image\"]\n",
    "    _image = four_rooms_to_rgb(_image)\n",
    "    image_tokens = [tokenizer.encode_image(image) for image in image_transform(_image)]\n",
    "    action_tokens = [\n",
    "        tokenizer.encode_discrete([tokenizer.separator, action])\n",
    "        for action in obs[\"action\"]\n",
    "    ]\n",
    "\n",
    "    mission = torch.stack(mission_tokens)\n",
    "    direction = torch.stack(direction_tokens)\n",
    "    image = torch.stack(image_tokens)\n",
    "    action = torch.stack(action_tokens)\n",
    "    xs = Timesteps({\n",
    "        \"mission\": mission,\n",
    "        \"direction\": direction,\n",
    "        \"image\": image,\n",
    "        \"action\": action,\n",
    "    })\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32645aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timesteps([('mission',\n",
       "            tensor([[[16250],\n",
       "                     [  262],\n",
       "                     [ 3061]]])),\n",
       "           ('direction', tensor([[[50260]]])),\n",
       "           ('image',\n",
       "            tensor([[[-0.2500, -0.2500, -0.2500,  ...,  0.0850,  0.0850,  0.0850],\n",
       "                     [-0.2500, -0.2500, -0.2500,  ...,  0.0850,  0.0850,  0.0850],\n",
       "                     [-0.2500, -0.2500, -0.2500,  ...,  0.0850,  0.0850,  0.0850],\n",
       "                     ...,\n",
       "                     [ 0.2500,  0.2500,  0.2500,  ..., -0.2230, -0.2230, -0.2230],\n",
       "                     [ 0.2500,  0.2500,  0.2500,  ..., -0.2230, -0.2230, -0.2230],\n",
       "                     [ 0.2500,  0.2500,  0.2500,  ..., -0.2230, -0.2230, -0.2230]]])),\n",
       "           ('action',\n",
       "            tensor([[[51280],\n",
       "                     [50257]]]))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = tokenize(obs)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9acd7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add batch dimension.\n",
    "xs = Timesteps([\n",
    "    (k, torch.stack([v])) for k, v in xs.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "982d72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_four_rooms(embedder, xs, ys=None, ms=None, sequence_length=1024, pad=True):\n",
    "    embeddings = torch.concat([embedder.embed(v) for k, v in xs.items()], dim=2)\n",
    "    B, E, T, C = embeddings.shape\n",
    "    embeddings = embeddings.view(B, E * T, C)\n",
    "    # Slice off final actions, so we can predict it.\n",
    "    return embeddings[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c2ce3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_token = None\n",
    "i = 0\n",
    "xs = xs.to(device)\n",
    "logits, loss = untrained_model(xs, pad=False, sequence=sequence_four_rooms)\n",
    "temp = 0.6\n",
    "scaled_logits = logits / temp\n",
    "probs = scaled_logits.softmax(dim=2)\n",
    "next_token = torch.multinomial(probs[0, [-1]], num_samples=1)\n",
    "next_token = tokenizer.decode_discrete(next_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fd4c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2165]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3286423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(token, action_space):\n",
    "    return token % tokenizer.n_text % env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3313589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU memory:\n",
      "Allocated: 5.22GB\n",
      "Cached: 6.89GB\n"
     ]
    }
   ],
   "source": [
    "# Track memory usage\n",
    "import gc\n",
    "import torch.cuda\n",
    "\n",
    "def print_gpu_memory():\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated()/1e9:.2f}GB\")\n",
    "    print(f\"Cached: {torch.cuda.memory_reserved()/1e9:.2f}GB\")\n",
    "\n",
    "print(\"Initial GPU memory:\")\n",
    "print_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8768bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next token: [2970]\n",
      "Next token: [25720]\n",
      "Next token: [40118]\n",
      "Next token: [30150]\n",
      "Next token: [41947]\n",
      "Next token: [35754]\n",
      "Next token: [49789]\n",
      "Next token: [24458]\n",
      "Next token: [20414]\n",
      "Next token: [24190]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    # Clear memory before each iteration\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Step with the previously predicted action: `next_token[0]`\n",
    "    obs, reward, terminated, truncated, info = env.step(get_action(next_token[0], env))\n",
    "    \n",
    "    # Prepare the next observation.\n",
    "    obs['direction'] = np.array([obs['direction']])\n",
    "    obs['image'] = np.array([obs['image']])\n",
    "    obs['mission'] = [obs['mission']]\n",
    "    # Prepare a temporary action token. Will be sliced off after sequencing.\n",
    "    # We just need this because each modality of the episodes need to have \n",
    "    # the same `E` dimension (remember - (B, E, T, C)), so that we can \n",
    "    # concatenate them on the `T` dimension.\n",
    "    dummy_action = 0\n",
    "    obs['action'] = np.array([dummy_action])\n",
    "    \n",
    "    # Move old tensors to CPU to free GPU memory\n",
    "    xs = xs.to(\"cpu\")\n",
    "    \n",
    "    xs_new = tokenize(obs)\n",
    "    # Merge the new episode.\n",
    "    xs = Timesteps([\n",
    "        (k, torch.concat([xs[k], xs_new[k].to(\"cpu\").unsqueeze(0)])) for k in xs.keys()\n",
    "    ])\n",
    "    \n",
    "    # Only move to GPU right before model inference\n",
    "    xs = xs.to(device)\n",
    "    \n",
    "    # Predict the next action\n",
    "    with torch.no_grad():  # Use mixed precision to reduce memory\n",
    "        logits, loss = untrained_model(xs, pad=False, sequence=sequence_four_rooms)\n",
    "    \n",
    "    temp = 0.8\n",
    "    scaled_logits = logits / temp\n",
    "    probs = scaled_logits.softmax(dim=2)\n",
    "    next_token = torch.multinomial(probs[0, [-1]], num_samples=1)\n",
    "    next_token = tokenizer.decode_discrete(next_token)\n",
    "    \n",
    "    # Move tensors back to CPU and clear GPU cache\n",
    "    xs = xs.to(\"cpu\")\n",
    "    logits = logits.to(\"cpu\")\n",
    "    probs = probs.to(\"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Next token: {next_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4406218",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afea0034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5ca7c",
   "metadata": {},
   "source": [
    "# Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4355fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = data_home / \"out\"\n",
    "ckpt_path = os.path.join(out_dir, \"ckpt.pt\")\n",
    "checkpoint = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "\n",
    "state_dict = checkpoint[\"model\"]\n",
    "# fix the keys of the state dictionary :(\n",
    "# honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "unwanted_prefix = \"_orig_mod.\"\n",
    "for k, v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix) :]] = state_dict.pop(k)\n",
    "checkpoint_model_args = checkpoint[\"model_args\"]\n",
    "for k in [\"n_layer\", \"n_head\", \"n_embd\", \"block_size\", \"bias\", \"vocab_size\"]:\n",
    "    transformer_model_args[k] = checkpoint_model_args[k]\n",
    "\n",
    "transformer_config = TransformerConfig(**transformer_model_args)\n",
    "transformer = nn.ModuleDict(\n",
    "    dict(\n",
    "        wpe=nn.Embedding(transformer_config.block_size, transformer_config.n_embd),\n",
    "        drop=nn.Dropout(transformer_config.dropout),\n",
    "        h=nn.ModuleList(\n",
    "            [\n",
    "                Block(transformer_config)\n",
    "                for _ in range(transformer_config.n_layer)\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "mugato_config = MugatoConfig(**mugato_model_args)\n",
    "trained_model = Mugato(tokenizer, transformer, mugato_config)\n",
    "trained_model.load_state_dict(state_dict)\n",
    "iter_num = checkpoint[\"iter_num\"]\n",
    "best_val_loss = checkpoint[\"best_val_loss\"]\n",
    "\n",
    "trained_model = trained_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff345b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.eval()\n",
    "text = \"First Citizen:\\n\"\n",
    "tokens = torch.stack([torch.concat([torch.tensor([tokenizer.eot_token_id]).unsqueeze(0), tokenizer.encode_text(text)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb989fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Where\n"
     ]
    }
   ],
   "source": [
    "xs = OrderedDict(text=tokens)\n",
    "xs, ys, ms = generic_collate_fn([[xs, xs]])\n",
    "next_word_token = None\n",
    "i = 0\n",
    "xs, ys, ms = [x.to(device) for x in [xs, ys, ms]]\n",
    "logits, loss = trained_model(xs, pad=False)\n",
    "temp = 0.6\n",
    "scaled_logits = logits / temp\n",
    "probs = scaled_logits.softmax(dim=2)\n",
    "next_word_token = torch.multinomial(probs[0, [-1]], num_samples=1)\n",
    "next_word = tokenizer.decode_text(next_word_token)\n",
    "text += next_word\n",
    "tokens = torch.stack([tokenizer.encode_text(text)])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86daa96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = test_data.recover_environment(render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "obs['direction'] = np.array([obs['direction']])\n",
    "obs['image'] = np.array([obs['image']])\n",
    "obs['mission'] = [obs['mission']]\n",
    "dummy_action = 0  # Will be sliced off after sequencing.\n",
    "obs['action'] = np.array([dummy_action])\n",
    "xs = tokenize(obs)\n",
    "# Add batch dimension.\n",
    "xs = Timesteps([\n",
    "    (k, torch.stack([v])) for k, v in xs.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f825748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word_token = None\n",
    "i = 0\n",
    "xs = xs.to(device)\n",
    "logits, loss = trained_model(xs, pad=False, sequence=sequence_four_rooms)\n",
    "temp = 0.6\n",
    "scaled_logits = logits / temp\n",
    "probs = scaled_logits.softmax(dim=2)\n",
    "next_token = torch.multinomial(probs[0, [-1]], num_samples=1)\n",
    "next_token = tokenizer.decode_discrete(next_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b0e8182",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "cannot convert without pygame.display initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step with the previously predicted action: `next_token[0]`\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_token\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Prepare the next observation.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m obs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirection\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([obs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirection\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[0;32m~/.virtualenvs/mugato/lib/python3.12/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/mugato/lib/python3.12/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/mugato/lib/python3.12/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/mugato/lib/python3.12/site-packages/minigrid/minigrid_env.py:582\u001b[0m, in \u001b[0;36mMiniGridEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    579\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_obs()\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, reward, terminated, truncated, {}\n",
      "File \u001b[0;32m~/.virtualenvs/mugato/lib/python3.12/site-packages/minigrid/minigrid_env.py:756\u001b[0m, in \u001b[0;36mMiniGridEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# offset = 32 if self.agent_pov else 64\u001b[39;00m\n\u001b[1;32m    753\u001b[0m bg \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mSurface(\n\u001b[1;32m    754\u001b[0m     (\u001b[38;5;28mint\u001b[39m(surf\u001b[38;5;241m.\u001b[39mget_size()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m offset), \u001b[38;5;28mint\u001b[39m(surf\u001b[38;5;241m.\u001b[39mget_size()[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m offset))\n\u001b[1;32m    755\u001b[0m )\n\u001b[0;32m--> 756\u001b[0m \u001b[43mbg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m bg\u001b[38;5;241m.\u001b[39mfill((\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m))\n\u001b[1;32m    758\u001b[0m bg\u001b[38;5;241m.\u001b[39mblit(surf, (offset \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31merror\u001b[0m: cannot convert without pygame.display initialized"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    # Clear memory before each iteration\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Step with the previously predicted action: `next_token[0]`\n",
    "    obs, reward, terminated, truncated, info = env.step(get_action(next_token[0], env))\n",
    "    \n",
    "    # Prepare the next observation.\n",
    "    obs['direction'] = np.array([obs['direction']])\n",
    "    obs['image'] = np.array([obs['image']])\n",
    "    obs['mission'] = [obs['mission']]\n",
    "    # Prepare a temporary action token. Will be sliced off after sequencing.\n",
    "    # We just need this because each modality of the episodes need to have \n",
    "    # the same `E` dimension (remember - (B, E, T, C)), so that we can \n",
    "    # concatenate them on the `T` dimension.\n",
    "    dummy_action = 0\n",
    "    obs['action'] = np.array([dummy_action])\n",
    "    \n",
    "    # Move old tensors to CPU to free GPU memory\n",
    "    xs = xs.to(\"cpu\")\n",
    "    \n",
    "    xs_new = tokenize(obs)\n",
    "    # Merge the new episode.\n",
    "    xs = Timesteps([\n",
    "        (k, torch.concat([xs[k], xs_new[k].to(\"cpu\").unsqueeze(0)])) for k in xs.keys()\n",
    "    ])\n",
    "    \n",
    "    # Only move to GPU right before model inference\n",
    "    xs = xs.to(device)\n",
    "    \n",
    "    # Predict the next action\n",
    "    with torch.no_grad():  # Use mixed precision to reduce memory\n",
    "        logits, loss = trained_model(xs, pad=False, sequence=sequence_four_rooms)\n",
    "    \n",
    "    temp = 0.8\n",
    "    scaled_logits = logits / temp\n",
    "    probs = scaled_logits.softmax(dim=2)\n",
    "    next_token = torch.multinomial(probs[0, [-1]], num_samples=1)\n",
    "    next_token = tokenizer.decode_discrete(next_token)\n",
    "    \n",
    "    # Move tensors back to CPU and clear GPU cache\n",
    "    xs = xs.to(\"cpu\")\n",
    "    logits = logits.to(\"cpu\")\n",
    "    probs = probs.to(\"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Next token: {next_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fc18534",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af869a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f634b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
