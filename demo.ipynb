{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2b4b6-102b-4578-9360-4c1600ad9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639aef4-2008-492b-af67-abf0248867f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mugato.data.utils import create_combined_dataloader\n",
    "from mugato.mugato import MugatoConfig, Mugato, TransformerConfig\n",
    "from mugato.nano_gpt import GPTConfig, GPT, Block, LayerNorm\n",
    "from mugato.utils import data_home, select_device, generic_collate_fn\n",
    "from mugato.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7985ced-942a-45b6-a15f-2aa63999f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = data_home / \"out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861caa9-23ac-450f-a243-4a9e8de64df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(out_dir, \"ckpt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc94fb-8dab-4c96-8b8f-7795da09c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 6\n",
    "n_head = 4\n",
    "n_embd = 512\n",
    "bias = False\n",
    "dropout = 0.0\n",
    "\n",
    "block_size=768\n",
    "batch_size=4\n",
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b09b1c7-35cd-43ca-a24b-9068da015ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer = tiktoken.get_encoding(\"r50k_base\")\n",
    "tokenizer = Tokenizer(text_tokenizer)\n",
    "train_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"train\", block_size=block_size))\n",
    "val_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"val\", block_size=block_size))\n",
    "test_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"test\", block_size=block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf51e28-6b8d-4099-a27f-6fbbe359ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "transformer_model_args = dict(\n",
    "    n_layer=n_layer,\n",
    "    n_head=n_head,\n",
    "    n_embd=n_embd,\n",
    "    block_size=block_size,\n",
    "    bias=bias,\n",
    "    vocab_size=50257,  # tiktoken.get_encoding(\"r50k_base\").n_vocab\n",
    "    dropout=dropout,\n",
    ")  # start with model_args from command line\n",
    "\n",
    "mugato_model_args = dict(\n",
    "    n_embd=n_embd,\n",
    "    block_size=block_size,\n",
    "    vocab_size=51281,  # text vocab + discrete vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150a25a-67c6-43b4-9281-e78459805552",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "checkpoint_model_args = checkpoint[\"model_args\"]\n",
    "# force these config attributes to be equal otherwise we can't even resume training\n",
    "# the rest of the attributes (e.g. dropout) can stay as desired from command line\n",
    "for k in [\"n_layer\", \"n_head\", \"n_embd\", \"block_size\", \"bias\", \"vocab_size\"]:\n",
    "    transformer_model_args[k] = checkpoint_model_args[k]\n",
    "# create the model\n",
    "transformer_config = TransformerConfig(**transformer_model_args)\n",
    "transformer = nn.ModuleDict(\n",
    "    dict(\n",
    "        wpe=nn.Embedding(transformer_config.block_size, transformer_config.n_embd),\n",
    "        drop=nn.Dropout(transformer_config.dropout),\n",
    "        h=nn.ModuleList(\n",
    "            [\n",
    "                Block(transformer_config)\n",
    "                for _ in range(transformer_config.n_layer)\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "mugato_config = MugatoConfig(**mugato_model_args)\n",
    "model = Mugato(tokenizer, transformer, mugato_config)\n",
    "state_dict = checkpoint[\"model\"]\n",
    "# fix the keys of the state dictionary :(\n",
    "# honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "unwanted_prefix = \"_orig_mod.\"\n",
    "for k, v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix) :]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "iter_num = checkpoint[\"iter_num\"]\n",
    "best_val_loss = checkpoint[\"best_val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b1d3e-b3b6-43ef-8d5e-ecd92ce103eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f49c8-9c2f-4786-ae69-e781815a58a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c979c4ef-d03d-4643-b833-8b119105594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0e788-1c92-4fde-b004-a1b83254ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "text = \"First Citizen:\\n\"\n",
    "tokens = torch.stack([torch.concat([torch.tensor([tokenizer.eot_token_id]).unsqueeze(0), tokenizer.encode_text(text)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586a42e-e03b-43d9-84e2-bc765da8060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = OrderedDict(text=tokens)\n",
    "xs, ys, ms = generic_collate_fn([[xs, ys]])\n",
    "next_word_token = None\n",
    "i = 0\n",
    "xs, ys, ms = [x.to(device) for x in [xs, ys, ms]]\n",
    "logits, loss = model(xs, pad=False)\n",
    "temp = 0.6\n",
    "scaled_logits = logits / temp\n",
    "probs = scaled_logits.softmax(dim=2)\n",
    "next_word_token = torch.multinomial(probs[0, [-1]], num_samples=1)\n",
    "next_word = tokenizer.decode_text(next_word_token)\n",
    "text += next_word\n",
    "tokens = torch.stack([tokenizer.encode_text(text)])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570fc6f-6fca-4941-9158-478cb478b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mugato.data.utils import create_combined_dataloader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf097b-d47c-4d53-92c1-f668807fcce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer = tiktoken.get_encoding(\"r50k_base\")\n",
    "tokenizer = Tokenizer(text_tokenizer)\n",
    "train_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"train\", block_size=block_size))\n",
    "val_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"val\", block_size=block_size))\n",
    "test_dataloader = iter(create_combined_dataloader(tokenizer, batch_size, split=\"test\", block_size=block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992876df-f0c2-433a-a04f-1d72dd3d7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, device):\n",
    "    if split == \"train\":\n",
    "        X, Y, M = next(next(train_dataloader))\n",
    "    elif split == \"val\":\n",
    "        X, Y, M = next(next(val_dataloader))\n",
    "    elif split == \"test\":\n",
    "        X, Y, M = next(next(test_dataloader))\n",
    "    X, Y, M = X.to(device), Y.to(device), M.to(device)\n",
    "    return X, Y, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207aceb6-d2b6-4c29-8487-d88e45516ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8677580-a9f3-4232-baec-d30b4613f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71389aa-287a-47b9-98b5-567bee65539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = (\n",
    "    \"bfloat16\"\n",
    "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    else \"float16\"\n",
    ")  # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "ptdtype = {\n",
    "    \"float32\": torch.float32,\n",
    "    \"bfloat16\": torch.bfloat16,\n",
    "    \"float16\": torch.float16,\n",
    "}[dtype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9123cb-b7ec-4fd4-a939-dc98dc05633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = (\n",
    "    nullcontext()\n",
    "    if device_type == \"cpu\"\n",
    "    else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a69dd-9f03-4f57-8078-e03176dde8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in tqdm(range(eval_iters)):\n",
    "            X, Y, M = get_batch(split, device)  # TODO: *Must* I return masks in get batch? Why?\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y, M)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae5a0b-b2a1-4335-b2dc-0591e9e7f5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3580b6a-08a5-49d8-b059-39aac0d17cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864acd5e-4587-4210-a73b-0d76aafd5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mugato.data.shakespeare import initialize, create_dataloader\n",
    "from mugato.tokenizer import Tokenizer\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d299cc-99dc-46ec-a18e-913c63bffb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataloader = create_dataloader(tokenizer, batch_size=batch_size, split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84104a0-5b0b-4e8c-9e41-a480c1b72493",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c8bd2-89bf-4dc8-ae16-06aab606be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, M = batch\n",
    "X, Y, M = X.to(device), Y.to(device), M.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edee894-01d0-4ce9-bbeb-f1c397b8ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss = model(X, Y, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791eb38-5185-4510-90d4-14b89b555043",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
